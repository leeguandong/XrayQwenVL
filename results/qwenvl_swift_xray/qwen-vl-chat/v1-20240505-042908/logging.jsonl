{"loss": 4.48069239, "acc": 0.35792518, "grad_norm": 3.828125, "learning_rate": 3.33e-06, "epoch": 0.00503145, "global_step": 1}
{"loss": 4.52559831, "acc": 0.34041935, "grad_norm": 4.09375, "learning_rate": 3.333e-05, "epoch": 0.05031447, "global_step": 10}
{"loss": 3.36858749, "acc": 0.39652653, "grad_norm": 1.3984375, "learning_rate": 6.667e-05, "epoch": 0.10062893, "global_step": 20}
{"loss": 2.35984173, "acc": 0.5008389, "grad_norm": 1.3515625, "learning_rate": 0.0001, "epoch": 0.1509434, "global_step": 30}
{"loss": 2.00753918, "acc": 0.5486455, "grad_norm": 1.15625, "learning_rate": 9.896e-05, "epoch": 0.20125786, "global_step": 40}
{"loss": 1.81973248, "acc": 0.56725512, "grad_norm": 1.109375, "learning_rate": 9.792e-05, "epoch": 0.25157233, "global_step": 50}
{"loss": 1.79023495, "acc": 0.57348714, "grad_norm": 1.0703125, "learning_rate": 9.688e-05, "epoch": 0.30188679, "global_step": 60}
{"loss": 1.72146225, "acc": 0.58238773, "grad_norm": 1.2109375, "learning_rate": 9.583e-05, "epoch": 0.35220126, "global_step": 70}
{"loss": 1.58067446, "acc": 0.60350637, "grad_norm": 1.3828125, "learning_rate": 9.479e-05, "epoch": 0.40251572, "global_step": 80}
{"loss": 1.64500809, "acc": 0.59458008, "grad_norm": 1.109375, "learning_rate": 9.375e-05, "epoch": 0.45283019, "global_step": 90}
{"loss": 1.55661736, "acc": 0.60787306, "grad_norm": 1.3359375, "learning_rate": 9.271e-05, "epoch": 0.50314465, "global_step": 100}
{"loss": 1.56103096, "acc": 0.60477295, "grad_norm": 1.296875, "learning_rate": 9.167e-05, "epoch": 0.55345912, "global_step": 110}
{"loss": 1.55453377, "acc": 0.60405235, "grad_norm": 1.5234375, "learning_rate": 9.063e-05, "epoch": 0.60377358, "global_step": 120}
{"loss": 1.53154507, "acc": 0.61138291, "grad_norm": 1.6171875, "learning_rate": 8.958e-05, "epoch": 0.65408805, "global_step": 130}
{"loss": 1.52059917, "acc": 0.61493511, "grad_norm": 1.5078125, "learning_rate": 8.854e-05, "epoch": 0.70440252, "global_step": 140}
{"loss": 1.4935092, "acc": 0.6185914, "grad_norm": 1.53125, "learning_rate": 8.75e-05, "epoch": 0.75471698, "global_step": 150}
{"loss": 1.49436073, "acc": 0.62048125, "grad_norm": 1.421875, "learning_rate": 8.646e-05, "epoch": 0.80503145, "global_step": 160}
{"loss": 1.49089794, "acc": 0.62400393, "grad_norm": 1.484375, "learning_rate": 8.542e-05, "epoch": 0.85534591, "global_step": 170}
{"loss": 1.40507154, "acc": 0.63742633, "grad_norm": 1.5703125, "learning_rate": 8.438e-05, "epoch": 0.90566038, "global_step": 180}
{"loss": 1.39483232, "acc": 0.63473172, "grad_norm": 1.515625, "learning_rate": 8.333e-05, "epoch": 0.95597484, "global_step": 190}
{"loss": 1.4571373, "acc": 0.62379017, "grad_norm": 1.4296875, "learning_rate": 8.229e-05, "epoch": 1.00628931, "global_step": 200}
{"loss": 1.4006216, "acc": 0.63763671, "grad_norm": 1.671875, "learning_rate": 8.125e-05, "epoch": 1.05660377, "global_step": 210}
{"loss": 1.35726681, "acc": 0.64623518, "grad_norm": 1.6640625, "learning_rate": 8.021e-05, "epoch": 1.10691824, "global_step": 220}
{"loss": 1.36130962, "acc": 0.64660139, "grad_norm": 1.6171875, "learning_rate": 7.917e-05, "epoch": 1.1572327, "global_step": 230}
{"loss": 1.35630322, "acc": 0.63943715, "grad_norm": 1.7109375, "learning_rate": 7.813e-05, "epoch": 1.20754717, "global_step": 240}
{"loss": 1.32482462, "acc": 0.6509944, "grad_norm": 1.8984375, "learning_rate": 7.708e-05, "epoch": 1.25786164, "global_step": 250}
{"loss": 1.32668304, "acc": 0.65223727, "grad_norm": 1.78125, "learning_rate": 7.604e-05, "epoch": 1.3081761, "global_step": 260}
{"loss": 1.35992279, "acc": 0.63887272, "grad_norm": 1.890625, "learning_rate": 7.5e-05, "epoch": 1.35849057, "global_step": 270}
{"loss": 1.32854404, "acc": 0.64692817, "grad_norm": 1.96875, "learning_rate": 7.396e-05, "epoch": 1.40880503, "global_step": 280}
{"loss": 1.30504303, "acc": 0.6549881, "grad_norm": 1.90625, "learning_rate": 7.292e-05, "epoch": 1.4591195, "global_step": 290}
{"loss": 1.31133156, "acc": 0.65215788, "grad_norm": 1.8671875, "learning_rate": 7.187e-05, "epoch": 1.50943396, "global_step": 300}
{"loss": 1.31055508, "acc": 0.65409498, "grad_norm": 2.015625, "learning_rate": 7.083e-05, "epoch": 1.55974843, "global_step": 310}
{"loss": 1.27391224, "acc": 0.65717721, "grad_norm": 2.078125, "learning_rate": 6.979e-05, "epoch": 1.61006289, "global_step": 320}
{"loss": 1.25759382, "acc": 0.66044388, "grad_norm": 2.203125, "learning_rate": 6.875e-05, "epoch": 1.66037736, "global_step": 330}
{"loss": 1.30579948, "acc": 0.64948182, "grad_norm": 2.125, "learning_rate": 6.771e-05, "epoch": 1.71069182, "global_step": 340}
{"loss": 1.25139179, "acc": 0.66449022, "grad_norm": 1.953125, "learning_rate": 6.667e-05, "epoch": 1.76100629, "global_step": 350}
{"loss": 1.27490225, "acc": 0.65693283, "grad_norm": 2.109375, "learning_rate": 6.563e-05, "epoch": 1.81132075, "global_step": 360}
{"loss": 1.28073511, "acc": 0.6558342, "grad_norm": 2.09375, "learning_rate": 6.458e-05, "epoch": 1.86163522, "global_step": 370}
{"loss": 1.25887384, "acc": 0.65924997, "grad_norm": 2.28125, "learning_rate": 6.354e-05, "epoch": 1.91194969, "global_step": 380}
{"loss": 1.2434267, "acc": 0.66663504, "grad_norm": 2.109375, "learning_rate": 6.25e-05, "epoch": 1.96226415, "global_step": 390}
{"loss": 1.20375528, "acc": 0.67453065, "grad_norm": 2.1875, "learning_rate": 6.146e-05, "epoch": 2.01257862, "global_step": 400}
{"loss": 1.10296974, "acc": 0.69613857, "grad_norm": 2.796875, "learning_rate": 6.042e-05, "epoch": 2.06289308, "global_step": 410}
{"loss": 1.1419445, "acc": 0.68712835, "grad_norm": 2.5, "learning_rate": 5.937e-05, "epoch": 2.11320755, "global_step": 420}
{"loss": 1.11612244, "acc": 0.69560375, "grad_norm": 2.765625, "learning_rate": 5.833e-05, "epoch": 2.16352201, "global_step": 430}
{"loss": 1.08185406, "acc": 0.7032136, "grad_norm": 2.4375, "learning_rate": 5.729e-05, "epoch": 2.21383648, "global_step": 440}
{"loss": 1.13129711, "acc": 0.69179592, "grad_norm": 2.796875, "learning_rate": 5.625e-05, "epoch": 2.26415094, "global_step": 450}
{"loss": 1.10817566, "acc": 0.69704566, "grad_norm": 2.765625, "learning_rate": 5.521e-05, "epoch": 2.31446541, "global_step": 460}
{"loss": 1.1209919, "acc": 0.69373083, "grad_norm": 2.53125, "learning_rate": 5.417e-05, "epoch": 2.36477987, "global_step": 470}
{"loss": 1.08133392, "acc": 0.69915276, "grad_norm": 2.84375, "learning_rate": 5.313e-05, "epoch": 2.41509434, "global_step": 480}
{"loss": 1.09620447, "acc": 0.70328555, "grad_norm": 3.09375, "learning_rate": 5.208e-05, "epoch": 2.46540881, "global_step": 490}
{"loss": 1.10145006, "acc": 0.69386168, "grad_norm": 2.625, "learning_rate": 5.104e-05, "epoch": 2.51572327, "global_step": 500}
{"loss": 1.09908714, "acc": 0.70252738, "grad_norm": 2.828125, "learning_rate": 5e-05, "epoch": 2.56603774, "global_step": 510}
{"loss": 1.10869875, "acc": 0.69673443, "grad_norm": 3.0625, "learning_rate": 4.896e-05, "epoch": 2.6163522, "global_step": 520}
{"loss": 1.10360785, "acc": 0.69666939, "grad_norm": 3.15625, "learning_rate": 4.792e-05, "epoch": 2.66666667, "global_step": 530}
{"loss": 1.06053267, "acc": 0.70942111, "grad_norm": 3.21875, "learning_rate": 4.688e-05, "epoch": 2.71698113, "global_step": 540}
{"loss": 1.11005697, "acc": 0.69621105, "grad_norm": 3.21875, "learning_rate": 4.583e-05, "epoch": 2.7672956, "global_step": 550}
{"loss": 1.07346964, "acc": 0.70517683, "grad_norm": 3.140625, "learning_rate": 4.479e-05, "epoch": 2.81761006, "global_step": 560}
{"loss": 1.07415762, "acc": 0.70620279, "grad_norm": 3.15625, "learning_rate": 4.375e-05, "epoch": 2.86792453, "global_step": 570}
{"loss": 1.054006, "acc": 0.71239042, "grad_norm": 3.34375, "learning_rate": 4.271e-05, "epoch": 2.91823899, "global_step": 580}
{"loss": 1.03590345, "acc": 0.71305399, "grad_norm": 3.234375, "learning_rate": 4.167e-05, "epoch": 2.96855346, "global_step": 590}
{"loss": 1.02116022, "acc": 0.71916242, "grad_norm": 3.1875, "learning_rate": 4.063e-05, "epoch": 3.01886792, "global_step": 600}
{"loss": 0.93118973, "acc": 0.74165769, "grad_norm": 3.78125, "learning_rate": 3.958e-05, "epoch": 3.06918239, "global_step": 610}
{"loss": 0.9097496, "acc": 0.74692011, "grad_norm": 3.703125, "learning_rate": 3.854e-05, "epoch": 3.11949686, "global_step": 620}
{"loss": 0.91313152, "acc": 0.74724779, "grad_norm": 3.75, "learning_rate": 3.75e-05, "epoch": 3.16981132, "global_step": 630}
{"loss": 0.89370852, "acc": 0.75153942, "grad_norm": 3.875, "learning_rate": 3.646e-05, "epoch": 3.22012579, "global_step": 640}
{"loss": 0.89566641, "acc": 0.75264025, "grad_norm": 3.53125, "learning_rate": 3.542e-05, "epoch": 3.27044025, "global_step": 650}
{"loss": 0.89889536, "acc": 0.74873405, "grad_norm": 3.6875, "learning_rate": 3.438e-05, "epoch": 3.32075472, "global_step": 660}
{"loss": 0.87628231, "acc": 0.75423079, "grad_norm": 3.84375, "learning_rate": 3.333e-05, "epoch": 3.37106918, "global_step": 670}
{"loss": 0.89561214, "acc": 0.75284452, "grad_norm": 3.703125, "learning_rate": 3.229e-05, "epoch": 3.42138365, "global_step": 680}
{"loss": 0.89204979, "acc": 0.75219603, "grad_norm": 3.703125, "learning_rate": 3.125e-05, "epoch": 3.47169811, "global_step": 690}
{"loss": 0.89397411, "acc": 0.75547881, "grad_norm": 4.15625, "learning_rate": 3.021e-05, "epoch": 3.52201258, "global_step": 700}
{"loss": 0.89460144, "acc": 0.75201845, "grad_norm": 3.9375, "learning_rate": 2.917e-05, "epoch": 3.57232704, "global_step": 710}
{"loss": 0.89762802, "acc": 0.75330639, "grad_norm": 4.0, "learning_rate": 2.813e-05, "epoch": 3.62264151, "global_step": 720}
{"loss": 0.83859186, "acc": 0.76659098, "grad_norm": 3.828125, "learning_rate": 2.708e-05, "epoch": 3.67295597, "global_step": 730}
{"loss": 0.86151867, "acc": 0.7623024, "grad_norm": 4.21875, "learning_rate": 2.604e-05, "epoch": 3.72327044, "global_step": 740}
{"loss": 0.86721306, "acc": 0.75714869, "grad_norm": 3.890625, "learning_rate": 2.5e-05, "epoch": 3.77358491, "global_step": 750}
{"loss": 0.86395082, "acc": 0.75858154, "grad_norm": 3.90625, "learning_rate": 2.396e-05, "epoch": 3.82389937, "global_step": 760}
{"loss": 0.86485796, "acc": 0.76084099, "grad_norm": 4.09375, "learning_rate": 2.292e-05, "epoch": 3.87421384, "global_step": 770}
{"loss": 0.84113998, "acc": 0.76386518, "grad_norm": 4.15625, "learning_rate": 2.187e-05, "epoch": 3.9245283, "global_step": 780}
{"loss": 0.83705759, "acc": 0.76792974, "grad_norm": 4.0, "learning_rate": 2.083e-05, "epoch": 3.97484277, "global_step": 790}
{"loss": 0.83809834, "acc": 0.77246685, "grad_norm": 3.765625, "learning_rate": 1.979e-05, "epoch": 4.02515723, "global_step": 800}
{"loss": 0.73750415, "acc": 0.79452448, "grad_norm": 4.40625, "learning_rate": 1.875e-05, "epoch": 4.0754717, "global_step": 810}
{"loss": 0.74755049, "acc": 0.79700141, "grad_norm": 4.1875, "learning_rate": 1.771e-05, "epoch": 4.12578616, "global_step": 820}
{"loss": 0.71598339, "acc": 0.80311651, "grad_norm": 4.375, "learning_rate": 1.667e-05, "epoch": 4.17610063, "global_step": 830}
{"loss": 0.72523293, "acc": 0.79688063, "grad_norm": 4.5, "learning_rate": 1.563e-05, "epoch": 4.22641509, "global_step": 840}
{"loss": 0.74284472, "acc": 0.79844427, "grad_norm": 4.28125, "learning_rate": 1.458e-05, "epoch": 4.27672956, "global_step": 850}
{"loss": 0.750599, "acc": 0.79428258, "grad_norm": 4.4375, "learning_rate": 1.354e-05, "epoch": 4.32704403, "global_step": 860}
{"loss": 0.74018383, "acc": 0.79566803, "grad_norm": 4.4375, "learning_rate": 1.25e-05, "epoch": 4.37735849, "global_step": 870}
{"loss": 0.7179245, "acc": 0.80367155, "grad_norm": 4.53125, "learning_rate": 1.146e-05, "epoch": 4.42767296, "global_step": 880}
{"loss": 0.73799438, "acc": 0.80155563, "grad_norm": 4.46875, "learning_rate": 1.042e-05, "epoch": 4.47798742, "global_step": 890}
{"loss": 0.73876877, "acc": 0.79835653, "grad_norm": 4.125, "learning_rate": 9.38e-06, "epoch": 4.52830189, "global_step": 900}
{"loss": 0.72253733, "acc": 0.79840956, "grad_norm": 4.34375, "learning_rate": 8.33e-06, "epoch": 4.57861635, "global_step": 910}
{"loss": 0.7410614, "acc": 0.79425635, "grad_norm": 4.09375, "learning_rate": 7.29e-06, "epoch": 4.62893082, "global_step": 920}
{"loss": 0.74439735, "acc": 0.79551425, "grad_norm": 4.34375, "learning_rate": 6.25e-06, "epoch": 4.67924528, "global_step": 930}
{"loss": 0.72431068, "acc": 0.80380936, "grad_norm": 4.15625, "learning_rate": 5.21e-06, "epoch": 4.72955975, "global_step": 940}
{"loss": 0.74081545, "acc": 0.79461656, "grad_norm": 4.15625, "learning_rate": 4.17e-06, "epoch": 4.77987421, "global_step": 950}
{"loss": 0.74980698, "acc": 0.79357677, "grad_norm": 4.46875, "learning_rate": 3.13e-06, "epoch": 4.83018868, "global_step": 960}
{"loss": 0.71733956, "acc": 0.80507946, "grad_norm": 4.34375, "learning_rate": 2.08e-06, "epoch": 4.88050314, "global_step": 970}
{"loss": 0.71620884, "acc": 0.80562067, "grad_norm": 4.375, "learning_rate": 1.04e-06, "epoch": 4.93081761, "global_step": 980}
{"loss": 0.74588747, "acc": 0.799578, "grad_norm": 4.125, "learning_rate": 0.0, "epoch": 4.98113208, "global_step": 990}
{"eval_loss": 1.04416406, "eval_acc": 0.7156441, "eval_runtime": 23.7999, "eval_samples_per_second": 2.731, "eval_steps_per_second": 0.714, "epoch": 4.98113208, "global_step": 990}
{"train_runtime": 23117.2147, "train_samples_per_second": 1.375, "train_steps_per_second": 0.043, "total_flos": 6.158400239163146e+17, "train_loss": 1.17931326, "epoch": 4.98113208, "global_step": 990}
{"memory": {"cuda:0": "0.00GiB", "cuda:1": "0.00GiB", "cuda:2": "30.77GiB", "cuda:3": "0.00GiB"}, "gen_time": 0.0, "gen_len": 0, "train_time": {"train_runtime": 23116.4396, "n_train_samples": 6358, "train_samples_per_second": 0.2750423555710543}, "last_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_metric": 1.04416406, "global_step": 990, "log_history": [{"loss": 4.48069239, "acc": 0.35792518, "grad_norm": 3.828125, "learning_rate": 3.3333333333333333e-06, "epoch": 0.005031446540880503, "step": 1}, {"loss": 4.52559831, "acc": 0.34041935, "grad_norm": 4.09375, "learning_rate": 3.3333333333333335e-05, "epoch": 0.050314465408805034, "step": 10}, {"loss": 3.36858749, "acc": 0.39652653, "grad_norm": 1.3984375, "learning_rate": 6.666666666666667e-05, "epoch": 0.10062893081761007, "step": 20}, {"loss": 2.35984173, "acc": 0.5008389, "grad_norm": 1.3515625, "learning_rate": 0.0001, "epoch": 0.1509433962264151, "step": 30}, {"loss": 2.00753918, "acc": 0.5486455, "grad_norm": 1.15625, "learning_rate": 9.895833333333334e-05, "epoch": 0.20125786163522014, "step": 40}, {"loss": 1.81973248, "acc": 0.56725512, "grad_norm": 1.109375, "learning_rate": 9.791666666666667e-05, "epoch": 0.25157232704402516, "step": 50}, {"loss": 1.79023495, "acc": 0.57348714, "grad_norm": 1.0703125, "learning_rate": 9.687500000000001e-05, "epoch": 0.3018867924528302, "step": 60}, {"loss": 1.72146225, "acc": 0.58238773, "grad_norm": 1.2109375, "learning_rate": 9.583333333333334e-05, "epoch": 0.3522012578616352, "step": 70}, {"loss": 1.58067446, "acc": 0.60350637, "grad_norm": 1.3828125, "learning_rate": 9.479166666666666e-05, "epoch": 0.4025157232704403, "step": 80}, {"loss": 1.64500809, "acc": 0.59458008, "grad_norm": 1.109375, "learning_rate": 9.375e-05, "epoch": 0.4528301886792453, "step": 90}, {"loss": 1.55661736, "acc": 0.60787306, "grad_norm": 1.3359375, "learning_rate": 9.270833333333334e-05, "epoch": 0.5031446540880503, "step": 100}, {"loss": 1.56103096, "acc": 0.60477295, "grad_norm": 1.296875, "learning_rate": 9.166666666666667e-05, "epoch": 0.5534591194968553, "step": 110}, {"loss": 1.55453377, "acc": 0.60405235, "grad_norm": 1.5234375, "learning_rate": 9.062500000000001e-05, "epoch": 0.6037735849056604, "step": 120}, {"loss": 1.53154507, "acc": 0.61138291, "grad_norm": 1.6171875, "learning_rate": 8.958333333333335e-05, "epoch": 0.6540880503144654, "step": 130}, {"loss": 1.52059917, "acc": 0.61493511, "grad_norm": 1.5078125, "learning_rate": 8.854166666666667e-05, "epoch": 0.7044025157232704, "step": 140}, {"loss": 1.4935092, "acc": 0.6185914, "grad_norm": 1.53125, "learning_rate": 8.75e-05, "epoch": 0.7547169811320755, "step": 150}, {"loss": 1.49436073, "acc": 0.62048125, "grad_norm": 1.421875, "learning_rate": 8.645833333333334e-05, "epoch": 0.8050314465408805, "step": 160}, {"loss": 1.49089794, "acc": 0.62400393, "grad_norm": 1.484375, "learning_rate": 8.541666666666666e-05, "epoch": 0.8553459119496856, "step": 170}, {"loss": 1.40507154, "acc": 0.63742633, "grad_norm": 1.5703125, "learning_rate": 8.4375e-05, "epoch": 0.9056603773584906, "step": 180}, {"loss": 1.39483232, "acc": 0.63473172, "grad_norm": 1.515625, "learning_rate": 8.333333333333334e-05, "epoch": 0.9559748427672956, "step": 190}, {"loss": 1.4571373, "acc": 0.62379017, "grad_norm": 1.4296875, "learning_rate": 8.229166666666667e-05, "epoch": 1.0062893081761006, "step": 200}, {"loss": 1.4006216, "acc": 0.63763671, "grad_norm": 1.671875, "learning_rate": 8.125000000000001e-05, "epoch": 1.0566037735849056, "step": 210}, {"loss": 1.35726681, "acc": 0.64623518, "grad_norm": 1.6640625, "learning_rate": 8.020833333333334e-05, "epoch": 1.1069182389937107, "step": 220}, {"loss": 1.36130962, "acc": 0.64660139, "grad_norm": 1.6171875, "learning_rate": 7.916666666666666e-05, "epoch": 1.1572327044025157, "step": 230}, {"loss": 1.35630322, "acc": 0.63943715, "grad_norm": 1.7109375, "learning_rate": 7.8125e-05, "epoch": 1.2075471698113207, "step": 240}, {"loss": 1.32482462, "acc": 0.6509944, "grad_norm": 1.8984375, "learning_rate": 7.708333333333334e-05, "epoch": 1.2578616352201257, "step": 250}, {"loss": 1.32668304, "acc": 0.65223727, "grad_norm": 1.78125, "learning_rate": 7.604166666666667e-05, "epoch": 1.3081761006289307, "step": 260}, {"loss": 1.35992279, "acc": 0.63887272, "grad_norm": 1.890625, "learning_rate": 7.500000000000001e-05, "epoch": 1.3584905660377358, "step": 270}, {"loss": 1.32854404, "acc": 0.64692817, "grad_norm": 1.96875, "learning_rate": 7.395833333333335e-05, "epoch": 1.408805031446541, "step": 280}, {"loss": 1.30504303, "acc": 0.6549881, "grad_norm": 1.90625, "learning_rate": 7.291666666666667e-05, "epoch": 1.459119496855346, "step": 290}, {"loss": 1.31133156, "acc": 0.65215788, "grad_norm": 1.8671875, "learning_rate": 7.1875e-05, "epoch": 1.509433962264151, "step": 300}, {"loss": 1.31055508, "acc": 0.65409498, "grad_norm": 2.015625, "learning_rate": 7.083333333333334e-05, "epoch": 1.559748427672956, "step": 310}, {"loss": 1.27391224, "acc": 0.65717721, "grad_norm": 2.078125, "learning_rate": 6.979166666666666e-05, "epoch": 1.610062893081761, "step": 320}, {"loss": 1.25759382, "acc": 0.66044388, "grad_norm": 2.203125, "learning_rate": 6.875e-05, "epoch": 1.6603773584905661, "step": 330}, {"loss": 1.30579948, "acc": 0.64948182, "grad_norm": 2.125, "learning_rate": 6.770833333333334e-05, "epoch": 1.7106918238993711, "step": 340}, {"loss": 1.25139179, "acc": 0.66449022, "grad_norm": 1.953125, "learning_rate": 6.666666666666667e-05, "epoch": 1.7610062893081762, "step": 350}, {"loss": 1.27490225, "acc": 0.65693283, "grad_norm": 2.109375, "learning_rate": 6.562500000000001e-05, "epoch": 1.8113207547169812, "step": 360}, {"loss": 1.28073511, "acc": 0.6558342, "grad_norm": 2.09375, "learning_rate": 6.458333333333334e-05, "epoch": 1.8616352201257862, "step": 370}, {"loss": 1.25887384, "acc": 0.65924997, "grad_norm": 2.28125, "learning_rate": 6.354166666666666e-05, "epoch": 1.9119496855345912, "step": 380}, {"loss": 1.2434267, "acc": 0.66663504, "grad_norm": 2.109375, "learning_rate": 6.25e-05, "epoch": 1.9622641509433962, "step": 390}, {"loss": 1.20375528, "acc": 0.67453065, "grad_norm": 2.1875, "learning_rate": 6.145833333333334e-05, "epoch": 2.0125786163522013, "step": 400}, {"loss": 1.10296974, "acc": 0.69613857, "grad_norm": 2.796875, "learning_rate": 6.041666666666667e-05, "epoch": 2.0628930817610063, "step": 410}, {"loss": 1.1419445, "acc": 0.68712835, "grad_norm": 2.5, "learning_rate": 5.9375e-05, "epoch": 2.1132075471698113, "step": 420}, {"loss": 1.11612244, "acc": 0.69560375, "grad_norm": 2.765625, "learning_rate": 5.833333333333334e-05, "epoch": 2.1635220125786163, "step": 430}, {"loss": 1.08185406, "acc": 0.7032136, "grad_norm": 2.4375, "learning_rate": 5.7291666666666666e-05, "epoch": 2.2138364779874213, "step": 440}, {"loss": 1.13129711, "acc": 0.69179592, "grad_norm": 2.796875, "learning_rate": 5.6250000000000005e-05, "epoch": 2.2641509433962264, "step": 450}, {"loss": 1.10817566, "acc": 0.69704566, "grad_norm": 2.765625, "learning_rate": 5.520833333333334e-05, "epoch": 2.3144654088050314, "step": 460}, {"loss": 1.1209919, "acc": 0.69373083, "grad_norm": 2.53125, "learning_rate": 5.4166666666666664e-05, "epoch": 2.3647798742138364, "step": 470}, {"loss": 1.08133392, "acc": 0.69915276, "grad_norm": 2.84375, "learning_rate": 5.3125000000000004e-05, "epoch": 2.4150943396226414, "step": 480}, {"loss": 1.09620447, "acc": 0.70328555, "grad_norm": 3.09375, "learning_rate": 5.208333333333334e-05, "epoch": 2.4654088050314464, "step": 490}, {"loss": 1.10145006, "acc": 0.69386168, "grad_norm": 2.625, "learning_rate": 5.104166666666666e-05, "epoch": 2.5157232704402515, "step": 500}, {"loss": 1.09908714, "acc": 0.70252738, "grad_norm": 2.828125, "learning_rate": 5e-05, "epoch": 2.5660377358490565, "step": 510}, {"loss": 1.10869875, "acc": 0.69673443, "grad_norm": 3.0625, "learning_rate": 4.8958333333333335e-05, "epoch": 2.6163522012578615, "step": 520}, {"loss": 1.10360785, "acc": 0.69666939, "grad_norm": 3.15625, "learning_rate": 4.791666666666667e-05, "epoch": 2.6666666666666665, "step": 530}, {"loss": 1.06053267, "acc": 0.70942111, "grad_norm": 3.21875, "learning_rate": 4.6875e-05, "epoch": 2.7169811320754715, "step": 540}, {"loss": 1.11005697, "acc": 0.69621105, "grad_norm": 3.21875, "learning_rate": 4.5833333333333334e-05, "epoch": 2.767295597484277, "step": 550}, {"loss": 1.07346964, "acc": 0.70517683, "grad_norm": 3.140625, "learning_rate": 4.4791666666666673e-05, "epoch": 2.817610062893082, "step": 560}, {"loss": 1.07415762, "acc": 0.70620279, "grad_norm": 3.15625, "learning_rate": 4.375e-05, "epoch": 2.867924528301887, "step": 570}, {"loss": 1.054006, "acc": 0.71239042, "grad_norm": 3.34375, "learning_rate": 4.270833333333333e-05, "epoch": 2.918238993710692, "step": 580}, {"loss": 1.03590345, "acc": 0.71305399, "grad_norm": 3.234375, "learning_rate": 4.166666666666667e-05, "epoch": 2.968553459119497, "step": 590}, {"loss": 1.02116022, "acc": 0.71916242, "grad_norm": 3.1875, "learning_rate": 4.0625000000000005e-05, "epoch": 3.018867924528302, "step": 600}, {"loss": 0.93118973, "acc": 0.74165769, "grad_norm": 3.78125, "learning_rate": 3.958333333333333e-05, "epoch": 3.069182389937107, "step": 610}, {"loss": 0.9097496, "acc": 0.74692011, "grad_norm": 3.703125, "learning_rate": 3.854166666666667e-05, "epoch": 3.119496855345912, "step": 620}, {"loss": 0.91313152, "acc": 0.74724779, "grad_norm": 3.75, "learning_rate": 3.7500000000000003e-05, "epoch": 3.169811320754717, "step": 630}, {"loss": 0.89370852, "acc": 0.75153942, "grad_norm": 3.875, "learning_rate": 3.6458333333333336e-05, "epoch": 3.220125786163522, "step": 640}, {"loss": 0.89566641, "acc": 0.75264025, "grad_norm": 3.53125, "learning_rate": 3.541666666666667e-05, "epoch": 3.270440251572327, "step": 650}, {"loss": 0.89889536, "acc": 0.74873405, "grad_norm": 3.6875, "learning_rate": 3.4375e-05, "epoch": 3.3207547169811322, "step": 660}, {"loss": 0.87628231, "acc": 0.75423079, "grad_norm": 3.84375, "learning_rate": 3.3333333333333335e-05, "epoch": 3.3710691823899372, "step": 670}, {"loss": 0.89561214, "acc": 0.75284452, "grad_norm": 3.703125, "learning_rate": 3.229166666666667e-05, "epoch": 3.4213836477987423, "step": 680}, {"loss": 0.89204979, "acc": 0.75219603, "grad_norm": 3.703125, "learning_rate": 3.125e-05, "epoch": 3.4716981132075473, "step": 690}, {"loss": 0.89397411, "acc": 0.75547881, "grad_norm": 4.15625, "learning_rate": 3.0208333333333334e-05, "epoch": 3.5220125786163523, "step": 700}, {"loss": 0.89460144, "acc": 0.75201845, "grad_norm": 3.9375, "learning_rate": 2.916666666666667e-05, "epoch": 3.5723270440251573, "step": 710}, {"loss": 0.89762802, "acc": 0.75330639, "grad_norm": 4.0, "learning_rate": 2.8125000000000003e-05, "epoch": 3.6226415094339623, "step": 720}, {"loss": 0.83859186, "acc": 0.76659098, "grad_norm": 3.828125, "learning_rate": 2.7083333333333332e-05, "epoch": 3.6729559748427674, "step": 730}, {"loss": 0.86151867, "acc": 0.7623024, "grad_norm": 4.21875, "learning_rate": 2.604166666666667e-05, "epoch": 3.7232704402515724, "step": 740}, {"loss": 0.86721306, "acc": 0.75714869, "grad_norm": 3.890625, "learning_rate": 2.5e-05, "epoch": 3.7735849056603774, "step": 750}, {"loss": 0.86395082, "acc": 0.75858154, "grad_norm": 3.90625, "learning_rate": 2.3958333333333334e-05, "epoch": 3.8238993710691824, "step": 760}, {"loss": 0.86485796, "acc": 0.76084099, "grad_norm": 4.09375, "learning_rate": 2.2916666666666667e-05, "epoch": 3.8742138364779874, "step": 770}, {"loss": 0.84113998, "acc": 0.76386518, "grad_norm": 4.15625, "learning_rate": 2.1875e-05, "epoch": 3.9245283018867925, "step": 780}, {"loss": 0.83705759, "acc": 0.76792974, "grad_norm": 4.0, "learning_rate": 2.0833333333333336e-05, "epoch": 3.9748427672955975, "step": 790}, {"loss": 0.83809834, "acc": 0.77246685, "grad_norm": 3.765625, "learning_rate": 1.9791666666666665e-05, "epoch": 4.0251572327044025, "step": 800}, {"loss": 0.73750415, "acc": 0.79452448, "grad_norm": 4.40625, "learning_rate": 1.8750000000000002e-05, "epoch": 4.0754716981132075, "step": 810}, {"loss": 0.74755049, "acc": 0.79700141, "grad_norm": 4.1875, "learning_rate": 1.7708333333333335e-05, "epoch": 4.1257861635220126, "step": 820}, {"loss": 0.71598339, "acc": 0.80311651, "grad_norm": 4.375, "learning_rate": 1.6666666666666667e-05, "epoch": 4.176100628930818, "step": 830}, {"loss": 0.72523293, "acc": 0.79688063, "grad_norm": 4.5, "learning_rate": 1.5625e-05, "epoch": 4.226415094339623, "step": 840}, {"loss": 0.74284472, "acc": 0.79844427, "grad_norm": 4.28125, "learning_rate": 1.4583333333333335e-05, "epoch": 4.276729559748428, "step": 850}, {"loss": 0.750599, "acc": 0.79428258, "grad_norm": 4.4375, "learning_rate": 1.3541666666666666e-05, "epoch": 4.327044025157233, "step": 860}, {"loss": 0.74018383, "acc": 0.79566803, "grad_norm": 4.4375, "learning_rate": 1.25e-05, "epoch": 4.377358490566038, "step": 870}, {"loss": 0.7179245, "acc": 0.80367155, "grad_norm": 4.53125, "learning_rate": 1.1458333333333333e-05, "epoch": 4.427672955974843, "step": 880}, {"loss": 0.73799438, "acc": 0.80155563, "grad_norm": 4.46875, "learning_rate": 1.0416666666666668e-05, "epoch": 4.477987421383648, "step": 890}, {"loss": 0.73876877, "acc": 0.79835653, "grad_norm": 4.125, "learning_rate": 9.375000000000001e-06, "epoch": 4.528301886792453, "step": 900}, {"loss": 0.72253733, "acc": 0.79840956, "grad_norm": 4.34375, "learning_rate": 8.333333333333334e-06, "epoch": 4.578616352201258, "step": 910}, {"loss": 0.7410614, "acc": 0.79425635, "grad_norm": 4.09375, "learning_rate": 7.2916666666666674e-06, "epoch": 4.628930817610063, "step": 920}, {"loss": 0.74439735, "acc": 0.79551425, "grad_norm": 4.34375, "learning_rate": 6.25e-06, "epoch": 4.679245283018868, "step": 930}, {"loss": 0.72431068, "acc": 0.80380936, "grad_norm": 4.15625, "learning_rate": 5.208333333333334e-06, "epoch": 4.729559748427673, "step": 940}, {"loss": 0.74081545, "acc": 0.79461656, "grad_norm": 4.15625, "learning_rate": 4.166666666666667e-06, "epoch": 4.779874213836478, "step": 950}, {"loss": 0.74980698, "acc": 0.79357677, "grad_norm": 4.46875, "learning_rate": 3.125e-06, "epoch": 4.830188679245283, "step": 960}, {"loss": 0.71733956, "acc": 0.80507946, "grad_norm": 4.34375, "learning_rate": 2.0833333333333334e-06, "epoch": 4.880503144654088, "step": 970}, {"loss": 0.71620884, "acc": 0.80562067, "grad_norm": 4.375, "learning_rate": 1.0416666666666667e-06, "epoch": 4.930817610062893, "step": 980}, {"loss": 0.74588747, "acc": 0.799578, "grad_norm": 4.125, "learning_rate": 0.0, "epoch": 4.981132075471698, "step": 990}, {"eval_loss": 1.0441640615463257, "eval_acc": 0.7156441023318995, "eval_runtime": 23.8006, "eval_samples_per_second": 2.731, "eval_steps_per_second": 0.714, "epoch": 4.981132075471698, "step": 990}, {"train_runtime": 23116.4396, "train_samples_per_second": 1.375, "train_steps_per_second": 0.043, "total_flos": 6.158400239163146e+17, "train_loss": 1.1793132555605186, "epoch": 4.981132075471698, "step": 990}], "model_info": "PeftModelForCausalLM: 9670.9599M Params (14.0247M Trainable [0.1450%]), 0.0000M Buffers.", "dataset_info": {"train_dataset": "358.053791\u00b120.710020, min=314.000000, max=518.000000, size=6358", "val_dataset": "359.076923\u00b118.445185, min=326.000000, max=412.000000, size=65"}}
{"memory": {"cuda:0": "0.00GiB", "cuda:1": "0.00GiB", "cuda:2": "0.00GiB", "cuda:3": "30.77GiB"}, "gen_time": 0.0, "gen_len": 0, "train_time": {"train_runtime": 23116.3673, "n_train_samples": 6358, "train_samples_per_second": 0.2750432158083939}, "last_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_metric": 1.04416406, "global_step": 990, "log_history": [{"loss": 4.48069239, "acc": 0.35792518, "grad_norm": 3.828125, "learning_rate": 3.3333333333333333e-06, "epoch": 0.005031446540880503, "step": 1}, {"loss": 4.52559831, "acc": 0.34041935, "grad_norm": 4.09375, "learning_rate": 3.3333333333333335e-05, "epoch": 0.050314465408805034, "step": 10}, {"loss": 3.36858749, "acc": 0.39652653, "grad_norm": 1.3984375, "learning_rate": 6.666666666666667e-05, "epoch": 0.10062893081761007, "step": 20}, {"loss": 2.35984173, "acc": 0.5008389, "grad_norm": 1.3515625, "learning_rate": 0.0001, "epoch": 0.1509433962264151, "step": 30}, {"loss": 2.00753918, "acc": 0.5486455, "grad_norm": 1.15625, "learning_rate": 9.895833333333334e-05, "epoch": 0.20125786163522014, "step": 40}, {"loss": 1.81973248, "acc": 0.56725512, "grad_norm": 1.109375, "learning_rate": 9.791666666666667e-05, "epoch": 0.25157232704402516, "step": 50}, {"loss": 1.79023495, "acc": 0.57348714, "grad_norm": 1.0703125, "learning_rate": 9.687500000000001e-05, "epoch": 0.3018867924528302, "step": 60}, {"loss": 1.72146225, "acc": 0.58238773, "grad_norm": 1.2109375, "learning_rate": 9.583333333333334e-05, "epoch": 0.3522012578616352, "step": 70}, {"loss": 1.58067446, "acc": 0.60350637, "grad_norm": 1.3828125, "learning_rate": 9.479166666666666e-05, "epoch": 0.4025157232704403, "step": 80}, {"loss": 1.64500809, "acc": 0.59458008, "grad_norm": 1.109375, "learning_rate": 9.375e-05, "epoch": 0.4528301886792453, "step": 90}, {"loss": 1.55661736, "acc": 0.60787306, "grad_norm": 1.3359375, "learning_rate": 9.270833333333334e-05, "epoch": 0.5031446540880503, "step": 100}, {"loss": 1.56103096, "acc": 0.60477295, "grad_norm": 1.296875, "learning_rate": 9.166666666666667e-05, "epoch": 0.5534591194968553, "step": 110}, {"loss": 1.55453377, "acc": 0.60405235, "grad_norm": 1.5234375, "learning_rate": 9.062500000000001e-05, "epoch": 0.6037735849056604, "step": 120}, {"loss": 1.53154507, "acc": 0.61138291, "grad_norm": 1.6171875, "learning_rate": 8.958333333333335e-05, "epoch": 0.6540880503144654, "step": 130}, {"loss": 1.52059917, "acc": 0.61493511, "grad_norm": 1.5078125, "learning_rate": 8.854166666666667e-05, "epoch": 0.7044025157232704, "step": 140}, {"loss": 1.4935092, "acc": 0.6185914, "grad_norm": 1.53125, "learning_rate": 8.75e-05, "epoch": 0.7547169811320755, "step": 150}, {"loss": 1.49436073, "acc": 0.62048125, "grad_norm": 1.421875, "learning_rate": 8.645833333333334e-05, "epoch": 0.8050314465408805, "step": 160}, {"loss": 1.49089794, "acc": 0.62400393, "grad_norm": 1.484375, "learning_rate": 8.541666666666666e-05, "epoch": 0.8553459119496856, "step": 170}, {"loss": 1.40507154, "acc": 0.63742633, "grad_norm": 1.5703125, "learning_rate": 8.4375e-05, "epoch": 0.9056603773584906, "step": 180}, {"loss": 1.39483232, "acc": 0.63473172, "grad_norm": 1.515625, "learning_rate": 8.333333333333334e-05, "epoch": 0.9559748427672956, "step": 190}, {"loss": 1.4571373, "acc": 0.62379017, "grad_norm": 1.4296875, "learning_rate": 8.229166666666667e-05, "epoch": 1.0062893081761006, "step": 200}, {"loss": 1.4006216, "acc": 0.63763671, "grad_norm": 1.671875, "learning_rate": 8.125000000000001e-05, "epoch": 1.0566037735849056, "step": 210}, {"loss": 1.35726681, "acc": 0.64623518, "grad_norm": 1.6640625, "learning_rate": 8.020833333333334e-05, "epoch": 1.1069182389937107, "step": 220}, {"loss": 1.36130962, "acc": 0.64660139, "grad_norm": 1.6171875, "learning_rate": 7.916666666666666e-05, "epoch": 1.1572327044025157, "step": 230}, {"loss": 1.35630322, "acc": 0.63943715, "grad_norm": 1.7109375, "learning_rate": 7.8125e-05, "epoch": 1.2075471698113207, "step": 240}, {"loss": 1.32482462, "acc": 0.6509944, "grad_norm": 1.8984375, "learning_rate": 7.708333333333334e-05, "epoch": 1.2578616352201257, "step": 250}, {"loss": 1.32668304, "acc": 0.65223727, "grad_norm": 1.78125, "learning_rate": 7.604166666666667e-05, "epoch": 1.3081761006289307, "step": 260}, {"loss": 1.35992279, "acc": 0.63887272, "grad_norm": 1.890625, "learning_rate": 7.500000000000001e-05, "epoch": 1.3584905660377358, "step": 270}, {"loss": 1.32854404, "acc": 0.64692817, "grad_norm": 1.96875, "learning_rate": 7.395833333333335e-05, "epoch": 1.408805031446541, "step": 280}, {"loss": 1.30504303, "acc": 0.6549881, "grad_norm": 1.90625, "learning_rate": 7.291666666666667e-05, "epoch": 1.459119496855346, "step": 290}, {"loss": 1.31133156, "acc": 0.65215788, "grad_norm": 1.8671875, "learning_rate": 7.1875e-05, "epoch": 1.509433962264151, "step": 300}, {"loss": 1.31055508, "acc": 0.65409498, "grad_norm": 2.015625, "learning_rate": 7.083333333333334e-05, "epoch": 1.559748427672956, "step": 310}, {"loss": 1.27391224, "acc": 0.65717721, "grad_norm": 2.078125, "learning_rate": 6.979166666666666e-05, "epoch": 1.610062893081761, "step": 320}, {"loss": 1.25759382, "acc": 0.66044388, "grad_norm": 2.203125, "learning_rate": 6.875e-05, "epoch": 1.6603773584905661, "step": 330}, {"loss": 1.30579948, "acc": 0.64948182, "grad_norm": 2.125, "learning_rate": 6.770833333333334e-05, "epoch": 1.7106918238993711, "step": 340}, {"loss": 1.25139179, "acc": 0.66449022, "grad_norm": 1.953125, "learning_rate": 6.666666666666667e-05, "epoch": 1.7610062893081762, "step": 350}, {"loss": 1.27490225, "acc": 0.65693283, "grad_norm": 2.109375, "learning_rate": 6.562500000000001e-05, "epoch": 1.8113207547169812, "step": 360}, {"loss": 1.28073511, "acc": 0.6558342, "grad_norm": 2.09375, "learning_rate": 6.458333333333334e-05, "epoch": 1.8616352201257862, "step": 370}, {"loss": 1.25887384, "acc": 0.65924997, "grad_norm": 2.28125, "learning_rate": 6.354166666666666e-05, "epoch": 1.9119496855345912, "step": 380}, {"loss": 1.2434267, "acc": 0.66663504, "grad_norm": 2.109375, "learning_rate": 6.25e-05, "epoch": 1.9622641509433962, "step": 390}, {"loss": 1.20375528, "acc": 0.67453065, "grad_norm": 2.1875, "learning_rate": 6.145833333333334e-05, "epoch": 2.0125786163522013, "step": 400}, {"loss": 1.10296974, "acc": 0.69613857, "grad_norm": 2.796875, "learning_rate": 6.041666666666667e-05, "epoch": 2.0628930817610063, "step": 410}, {"loss": 1.1419445, "acc": 0.68712835, "grad_norm": 2.5, "learning_rate": 5.9375e-05, "epoch": 2.1132075471698113, "step": 420}, {"loss": 1.11612244, "acc": 0.69560375, "grad_norm": 2.765625, "learning_rate": 5.833333333333334e-05, "epoch": 2.1635220125786163, "step": 430}, {"loss": 1.08185406, "acc": 0.7032136, "grad_norm": 2.4375, "learning_rate": 5.7291666666666666e-05, "epoch": 2.2138364779874213, "step": 440}, {"loss": 1.13129711, "acc": 0.69179592, "grad_norm": 2.796875, "learning_rate": 5.6250000000000005e-05, "epoch": 2.2641509433962264, "step": 450}, {"loss": 1.10817566, "acc": 0.69704566, "grad_norm": 2.765625, "learning_rate": 5.520833333333334e-05, "epoch": 2.3144654088050314, "step": 460}, {"loss": 1.1209919, "acc": 0.69373083, "grad_norm": 2.53125, "learning_rate": 5.4166666666666664e-05, "epoch": 2.3647798742138364, "step": 470}, {"loss": 1.08133392, "acc": 0.69915276, "grad_norm": 2.84375, "learning_rate": 5.3125000000000004e-05, "epoch": 2.4150943396226414, "step": 480}, {"loss": 1.09620447, "acc": 0.70328555, "grad_norm": 3.09375, "learning_rate": 5.208333333333334e-05, "epoch": 2.4654088050314464, "step": 490}, {"loss": 1.10145006, "acc": 0.69386168, "grad_norm": 2.625, "learning_rate": 5.104166666666666e-05, "epoch": 2.5157232704402515, "step": 500}, {"loss": 1.09908714, "acc": 0.70252738, "grad_norm": 2.828125, "learning_rate": 5e-05, "epoch": 2.5660377358490565, "step": 510}, {"loss": 1.10869875, "acc": 0.69673443, "grad_norm": 3.0625, "learning_rate": 4.8958333333333335e-05, "epoch": 2.6163522012578615, "step": 520}, {"loss": 1.10360785, "acc": 0.69666939, "grad_norm": 3.15625, "learning_rate": 4.791666666666667e-05, "epoch": 2.6666666666666665, "step": 530}, {"loss": 1.06053267, "acc": 0.70942111, "grad_norm": 3.21875, "learning_rate": 4.6875e-05, "epoch": 2.7169811320754715, "step": 540}, {"loss": 1.11005697, "acc": 0.69621105, "grad_norm": 3.21875, "learning_rate": 4.5833333333333334e-05, "epoch": 2.767295597484277, "step": 550}, {"loss": 1.07346964, "acc": 0.70517683, "grad_norm": 3.140625, "learning_rate": 4.4791666666666673e-05, "epoch": 2.817610062893082, "step": 560}, {"loss": 1.07415762, "acc": 0.70620279, "grad_norm": 3.15625, "learning_rate": 4.375e-05, "epoch": 2.867924528301887, "step": 570}, {"loss": 1.054006, "acc": 0.71239042, "grad_norm": 3.34375, "learning_rate": 4.270833333333333e-05, "epoch": 2.918238993710692, "step": 580}, {"loss": 1.03590345, "acc": 0.71305399, "grad_norm": 3.234375, "learning_rate": 4.166666666666667e-05, "epoch": 2.968553459119497, "step": 590}, {"loss": 1.02116022, "acc": 0.71916242, "grad_norm": 3.1875, "learning_rate": 4.0625000000000005e-05, "epoch": 3.018867924528302, "step": 600}, {"loss": 0.93118973, "acc": 0.74165769, "grad_norm": 3.78125, "learning_rate": 3.958333333333333e-05, "epoch": 3.069182389937107, "step": 610}, {"loss": 0.9097496, "acc": 0.74692011, "grad_norm": 3.703125, "learning_rate": 3.854166666666667e-05, "epoch": 3.119496855345912, "step": 620}, {"loss": 0.91313152, "acc": 0.74724779, "grad_norm": 3.75, "learning_rate": 3.7500000000000003e-05, "epoch": 3.169811320754717, "step": 630}, {"loss": 0.89370852, "acc": 0.75153942, "grad_norm": 3.875, "learning_rate": 3.6458333333333336e-05, "epoch": 3.220125786163522, "step": 640}, {"loss": 0.89566641, "acc": 0.75264025, "grad_norm": 3.53125, "learning_rate": 3.541666666666667e-05, "epoch": 3.270440251572327, "step": 650}, {"loss": 0.89889536, "acc": 0.74873405, "grad_norm": 3.6875, "learning_rate": 3.4375e-05, "epoch": 3.3207547169811322, "step": 660}, {"loss": 0.87628231, "acc": 0.75423079, "grad_norm": 3.84375, "learning_rate": 3.3333333333333335e-05, "epoch": 3.3710691823899372, "step": 670}, {"loss": 0.89561214, "acc": 0.75284452, "grad_norm": 3.703125, "learning_rate": 3.229166666666667e-05, "epoch": 3.4213836477987423, "step": 680}, {"loss": 0.89204979, "acc": 0.75219603, "grad_norm": 3.703125, "learning_rate": 3.125e-05, "epoch": 3.4716981132075473, "step": 690}, {"loss": 0.89397411, "acc": 0.75547881, "grad_norm": 4.15625, "learning_rate": 3.0208333333333334e-05, "epoch": 3.5220125786163523, "step": 700}, {"loss": 0.89460144, "acc": 0.75201845, "grad_norm": 3.9375, "learning_rate": 2.916666666666667e-05, "epoch": 3.5723270440251573, "step": 710}, {"loss": 0.89762802, "acc": 0.75330639, "grad_norm": 4.0, "learning_rate": 2.8125000000000003e-05, "epoch": 3.6226415094339623, "step": 720}, {"loss": 0.83859186, "acc": 0.76659098, "grad_norm": 3.828125, "learning_rate": 2.7083333333333332e-05, "epoch": 3.6729559748427674, "step": 730}, {"loss": 0.86151867, "acc": 0.7623024, "grad_norm": 4.21875, "learning_rate": 2.604166666666667e-05, "epoch": 3.7232704402515724, "step": 740}, {"loss": 0.86721306, "acc": 0.75714869, "grad_norm": 3.890625, "learning_rate": 2.5e-05, "epoch": 3.7735849056603774, "step": 750}, {"loss": 0.86395082, "acc": 0.75858154, "grad_norm": 3.90625, "learning_rate": 2.3958333333333334e-05, "epoch": 3.8238993710691824, "step": 760}, {"loss": 0.86485796, "acc": 0.76084099, "grad_norm": 4.09375, "learning_rate": 2.2916666666666667e-05, "epoch": 3.8742138364779874, "step": 770}, {"loss": 0.84113998, "acc": 0.76386518, "grad_norm": 4.15625, "learning_rate": 2.1875e-05, "epoch": 3.9245283018867925, "step": 780}, {"loss": 0.83705759, "acc": 0.76792974, "grad_norm": 4.0, "learning_rate": 2.0833333333333336e-05, "epoch": 3.9748427672955975, "step": 790}, {"loss": 0.83809834, "acc": 0.77246685, "grad_norm": 3.765625, "learning_rate": 1.9791666666666665e-05, "epoch": 4.0251572327044025, "step": 800}, {"loss": 0.73750415, "acc": 0.79452448, "grad_norm": 4.40625, "learning_rate": 1.8750000000000002e-05, "epoch": 4.0754716981132075, "step": 810}, {"loss": 0.74755049, "acc": 0.79700141, "grad_norm": 4.1875, "learning_rate": 1.7708333333333335e-05, "epoch": 4.1257861635220126, "step": 820}, {"loss": 0.71598339, "acc": 0.80311651, "grad_norm": 4.375, "learning_rate": 1.6666666666666667e-05, "epoch": 4.176100628930818, "step": 830}, {"loss": 0.72523293, "acc": 0.79688063, "grad_norm": 4.5, "learning_rate": 1.5625e-05, "epoch": 4.226415094339623, "step": 840}, {"loss": 0.74284472, "acc": 0.79844427, "grad_norm": 4.28125, "learning_rate": 1.4583333333333335e-05, "epoch": 4.276729559748428, "step": 850}, {"loss": 0.750599, "acc": 0.79428258, "grad_norm": 4.4375, "learning_rate": 1.3541666666666666e-05, "epoch": 4.327044025157233, "step": 860}, {"loss": 0.74018383, "acc": 0.79566803, "grad_norm": 4.4375, "learning_rate": 1.25e-05, "epoch": 4.377358490566038, "step": 870}, {"loss": 0.7179245, "acc": 0.80367155, "grad_norm": 4.53125, "learning_rate": 1.1458333333333333e-05, "epoch": 4.427672955974843, "step": 880}, {"loss": 0.73799438, "acc": 0.80155563, "grad_norm": 4.46875, "learning_rate": 1.0416666666666668e-05, "epoch": 4.477987421383648, "step": 890}, {"loss": 0.73876877, "acc": 0.79835653, "grad_norm": 4.125, "learning_rate": 9.375000000000001e-06, "epoch": 4.528301886792453, "step": 900}, {"loss": 0.72253733, "acc": 0.79840956, "grad_norm": 4.34375, "learning_rate": 8.333333333333334e-06, "epoch": 4.578616352201258, "step": 910}, {"loss": 0.7410614, "acc": 0.79425635, "grad_norm": 4.09375, "learning_rate": 7.2916666666666674e-06, "epoch": 4.628930817610063, "step": 920}, {"loss": 0.74439735, "acc": 0.79551425, "grad_norm": 4.34375, "learning_rate": 6.25e-06, "epoch": 4.679245283018868, "step": 930}, {"loss": 0.72431068, "acc": 0.80380936, "grad_norm": 4.15625, "learning_rate": 5.208333333333334e-06, "epoch": 4.729559748427673, "step": 940}, {"loss": 0.74081545, "acc": 0.79461656, "grad_norm": 4.15625, "learning_rate": 4.166666666666667e-06, "epoch": 4.779874213836478, "step": 950}, {"loss": 0.74980698, "acc": 0.79357677, "grad_norm": 4.46875, "learning_rate": 3.125e-06, "epoch": 4.830188679245283, "step": 960}, {"loss": 0.71733956, "acc": 0.80507946, "grad_norm": 4.34375, "learning_rate": 2.0833333333333334e-06, "epoch": 4.880503144654088, "step": 970}, {"loss": 0.71620884, "acc": 0.80562067, "grad_norm": 4.375, "learning_rate": 1.0416666666666667e-06, "epoch": 4.930817610062893, "step": 980}, {"loss": 0.74588747, "acc": 0.799578, "grad_norm": 4.125, "learning_rate": 0.0, "epoch": 4.981132075471698, "step": 990}, {"eval_loss": 1.0441640615463257, "eval_acc": 0.7156441023318995, "eval_runtime": 23.8005, "eval_samples_per_second": 2.731, "eval_steps_per_second": 0.714, "epoch": 4.981132075471698, "step": 990}, {"train_runtime": 23116.3673, "train_samples_per_second": 1.375, "train_steps_per_second": 0.043, "total_flos": 6.158400239163146e+17, "train_loss": 1.1793132555605186, "epoch": 4.981132075471698, "step": 990}], "model_info": "PeftModelForCausalLM: 9670.9599M Params (14.0247M Trainable [0.1450%]), 0.0000M Buffers.", "dataset_info": {"train_dataset": "358.053791\u00b120.710020, min=314.000000, max=518.000000, size=6358", "val_dataset": "359.076923\u00b118.445185, min=326.000000, max=412.000000, size=65"}}
{"memory": {"cuda:0": "0.00GiB", "cuda:1": "30.76GiB", "cuda:2": "0.00GiB", "cuda:3": "0.00GiB"}, "gen_time": 0.0, "gen_len": 0, "train_time": {"train_runtime": 23116.3719, "n_train_samples": 6358, "train_samples_per_second": 0.275043161076674}, "last_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_metric": 1.04416406, "global_step": 990, "log_history": [{"loss": 4.48069239, "acc": 0.35792518, "grad_norm": 3.828125, "learning_rate": 3.3333333333333333e-06, "epoch": 0.005031446540880503, "step": 1}, {"loss": 4.52559831, "acc": 0.34041935, "grad_norm": 4.09375, "learning_rate": 3.3333333333333335e-05, "epoch": 0.050314465408805034, "step": 10}, {"loss": 3.36858749, "acc": 0.39652653, "grad_norm": 1.3984375, "learning_rate": 6.666666666666667e-05, "epoch": 0.10062893081761007, "step": 20}, {"loss": 2.35984173, "acc": 0.5008389, "grad_norm": 1.3515625, "learning_rate": 0.0001, "epoch": 0.1509433962264151, "step": 30}, {"loss": 2.00753918, "acc": 0.5486455, "grad_norm": 1.15625, "learning_rate": 9.895833333333334e-05, "epoch": 0.20125786163522014, "step": 40}, {"loss": 1.81973248, "acc": 0.56725512, "grad_norm": 1.109375, "learning_rate": 9.791666666666667e-05, "epoch": 0.25157232704402516, "step": 50}, {"loss": 1.79023495, "acc": 0.57348714, "grad_norm": 1.0703125, "learning_rate": 9.687500000000001e-05, "epoch": 0.3018867924528302, "step": 60}, {"loss": 1.72146225, "acc": 0.58238773, "grad_norm": 1.2109375, "learning_rate": 9.583333333333334e-05, "epoch": 0.3522012578616352, "step": 70}, {"loss": 1.58067446, "acc": 0.60350637, "grad_norm": 1.3828125, "learning_rate": 9.479166666666666e-05, "epoch": 0.4025157232704403, "step": 80}, {"loss": 1.64500809, "acc": 0.59458008, "grad_norm": 1.109375, "learning_rate": 9.375e-05, "epoch": 0.4528301886792453, "step": 90}, {"loss": 1.55661736, "acc": 0.60787306, "grad_norm": 1.3359375, "learning_rate": 9.270833333333334e-05, "epoch": 0.5031446540880503, "step": 100}, {"loss": 1.56103096, "acc": 0.60477295, "grad_norm": 1.296875, "learning_rate": 9.166666666666667e-05, "epoch": 0.5534591194968553, "step": 110}, {"loss": 1.55453377, "acc": 0.60405235, "grad_norm": 1.5234375, "learning_rate": 9.062500000000001e-05, "epoch": 0.6037735849056604, "step": 120}, {"loss": 1.53154507, "acc": 0.61138291, "grad_norm": 1.6171875, "learning_rate": 8.958333333333335e-05, "epoch": 0.6540880503144654, "step": 130}, {"loss": 1.52059917, "acc": 0.61493511, "grad_norm": 1.5078125, "learning_rate": 8.854166666666667e-05, "epoch": 0.7044025157232704, "step": 140}, {"loss": 1.4935092, "acc": 0.6185914, "grad_norm": 1.53125, "learning_rate": 8.75e-05, "epoch": 0.7547169811320755, "step": 150}, {"loss": 1.49436073, "acc": 0.62048125, "grad_norm": 1.421875, "learning_rate": 8.645833333333334e-05, "epoch": 0.8050314465408805, "step": 160}, {"loss": 1.49089794, "acc": 0.62400393, "grad_norm": 1.484375, "learning_rate": 8.541666666666666e-05, "epoch": 0.8553459119496856, "step": 170}, {"loss": 1.40507154, "acc": 0.63742633, "grad_norm": 1.5703125, "learning_rate": 8.4375e-05, "epoch": 0.9056603773584906, "step": 180}, {"loss": 1.39483232, "acc": 0.63473172, "grad_norm": 1.515625, "learning_rate": 8.333333333333334e-05, "epoch": 0.9559748427672956, "step": 190}, {"loss": 1.4571373, "acc": 0.62379017, "grad_norm": 1.4296875, "learning_rate": 8.229166666666667e-05, "epoch": 1.0062893081761006, "step": 200}, {"loss": 1.4006216, "acc": 0.63763671, "grad_norm": 1.671875, "learning_rate": 8.125000000000001e-05, "epoch": 1.0566037735849056, "step": 210}, {"loss": 1.35726681, "acc": 0.64623518, "grad_norm": 1.6640625, "learning_rate": 8.020833333333334e-05, "epoch": 1.1069182389937107, "step": 220}, {"loss": 1.36130962, "acc": 0.64660139, "grad_norm": 1.6171875, "learning_rate": 7.916666666666666e-05, "epoch": 1.1572327044025157, "step": 230}, {"loss": 1.35630322, "acc": 0.63943715, "grad_norm": 1.7109375, "learning_rate": 7.8125e-05, "epoch": 1.2075471698113207, "step": 240}, {"loss": 1.32482462, "acc": 0.6509944, "grad_norm": 1.8984375, "learning_rate": 7.708333333333334e-05, "epoch": 1.2578616352201257, "step": 250}, {"loss": 1.32668304, "acc": 0.65223727, "grad_norm": 1.78125, "learning_rate": 7.604166666666667e-05, "epoch": 1.3081761006289307, "step": 260}, {"loss": 1.35992279, "acc": 0.63887272, "grad_norm": 1.890625, "learning_rate": 7.500000000000001e-05, "epoch": 1.3584905660377358, "step": 270}, {"loss": 1.32854404, "acc": 0.64692817, "grad_norm": 1.96875, "learning_rate": 7.395833333333335e-05, "epoch": 1.408805031446541, "step": 280}, {"loss": 1.30504303, "acc": 0.6549881, "grad_norm": 1.90625, "learning_rate": 7.291666666666667e-05, "epoch": 1.459119496855346, "step": 290}, {"loss": 1.31133156, "acc": 0.65215788, "grad_norm": 1.8671875, "learning_rate": 7.1875e-05, "epoch": 1.509433962264151, "step": 300}, {"loss": 1.31055508, "acc": 0.65409498, "grad_norm": 2.015625, "learning_rate": 7.083333333333334e-05, "epoch": 1.559748427672956, "step": 310}, {"loss": 1.27391224, "acc": 0.65717721, "grad_norm": 2.078125, "learning_rate": 6.979166666666666e-05, "epoch": 1.610062893081761, "step": 320}, {"loss": 1.25759382, "acc": 0.66044388, "grad_norm": 2.203125, "learning_rate": 6.875e-05, "epoch": 1.6603773584905661, "step": 330}, {"loss": 1.30579948, "acc": 0.64948182, "grad_norm": 2.125, "learning_rate": 6.770833333333334e-05, "epoch": 1.7106918238993711, "step": 340}, {"loss": 1.25139179, "acc": 0.66449022, "grad_norm": 1.953125, "learning_rate": 6.666666666666667e-05, "epoch": 1.7610062893081762, "step": 350}, {"loss": 1.27490225, "acc": 0.65693283, "grad_norm": 2.109375, "learning_rate": 6.562500000000001e-05, "epoch": 1.8113207547169812, "step": 360}, {"loss": 1.28073511, "acc": 0.6558342, "grad_norm": 2.09375, "learning_rate": 6.458333333333334e-05, "epoch": 1.8616352201257862, "step": 370}, {"loss": 1.25887384, "acc": 0.65924997, "grad_norm": 2.28125, "learning_rate": 6.354166666666666e-05, "epoch": 1.9119496855345912, "step": 380}, {"loss": 1.2434267, "acc": 0.66663504, "grad_norm": 2.109375, "learning_rate": 6.25e-05, "epoch": 1.9622641509433962, "step": 390}, {"loss": 1.20375528, "acc": 0.67453065, "grad_norm": 2.1875, "learning_rate": 6.145833333333334e-05, "epoch": 2.0125786163522013, "step": 400}, {"loss": 1.10296974, "acc": 0.69613857, "grad_norm": 2.796875, "learning_rate": 6.041666666666667e-05, "epoch": 2.0628930817610063, "step": 410}, {"loss": 1.1419445, "acc": 0.68712835, "grad_norm": 2.5, "learning_rate": 5.9375e-05, "epoch": 2.1132075471698113, "step": 420}, {"loss": 1.11612244, "acc": 0.69560375, "grad_norm": 2.765625, "learning_rate": 5.833333333333334e-05, "epoch": 2.1635220125786163, "step": 430}, {"loss": 1.08185406, "acc": 0.7032136, "grad_norm": 2.4375, "learning_rate": 5.7291666666666666e-05, "epoch": 2.2138364779874213, "step": 440}, {"loss": 1.13129711, "acc": 0.69179592, "grad_norm": 2.796875, "learning_rate": 5.6250000000000005e-05, "epoch": 2.2641509433962264, "step": 450}, {"loss": 1.10817566, "acc": 0.69704566, "grad_norm": 2.765625, "learning_rate": 5.520833333333334e-05, "epoch": 2.3144654088050314, "step": 460}, {"loss": 1.1209919, "acc": 0.69373083, "grad_norm": 2.53125, "learning_rate": 5.4166666666666664e-05, "epoch": 2.3647798742138364, "step": 470}, {"loss": 1.08133392, "acc": 0.69915276, "grad_norm": 2.84375, "learning_rate": 5.3125000000000004e-05, "epoch": 2.4150943396226414, "step": 480}, {"loss": 1.09620447, "acc": 0.70328555, "grad_norm": 3.09375, "learning_rate": 5.208333333333334e-05, "epoch": 2.4654088050314464, "step": 490}, {"loss": 1.10145006, "acc": 0.69386168, "grad_norm": 2.625, "learning_rate": 5.104166666666666e-05, "epoch": 2.5157232704402515, "step": 500}, {"loss": 1.09908714, "acc": 0.70252738, "grad_norm": 2.828125, "learning_rate": 5e-05, "epoch": 2.5660377358490565, "step": 510}, {"loss": 1.10869875, "acc": 0.69673443, "grad_norm": 3.0625, "learning_rate": 4.8958333333333335e-05, "epoch": 2.6163522012578615, "step": 520}, {"loss": 1.10360785, "acc": 0.69666939, "grad_norm": 3.15625, "learning_rate": 4.791666666666667e-05, "epoch": 2.6666666666666665, "step": 530}, {"loss": 1.06053267, "acc": 0.70942111, "grad_norm": 3.21875, "learning_rate": 4.6875e-05, "epoch": 2.7169811320754715, "step": 540}, {"loss": 1.11005697, "acc": 0.69621105, "grad_norm": 3.21875, "learning_rate": 4.5833333333333334e-05, "epoch": 2.767295597484277, "step": 550}, {"loss": 1.07346964, "acc": 0.70517683, "grad_norm": 3.140625, "learning_rate": 4.4791666666666673e-05, "epoch": 2.817610062893082, "step": 560}, {"loss": 1.07415762, "acc": 0.70620279, "grad_norm": 3.15625, "learning_rate": 4.375e-05, "epoch": 2.867924528301887, "step": 570}, {"loss": 1.054006, "acc": 0.71239042, "grad_norm": 3.34375, "learning_rate": 4.270833333333333e-05, "epoch": 2.918238993710692, "step": 580}, {"loss": 1.03590345, "acc": 0.71305399, "grad_norm": 3.234375, "learning_rate": 4.166666666666667e-05, "epoch": 2.968553459119497, "step": 590}, {"loss": 1.02116022, "acc": 0.71916242, "grad_norm": 3.1875, "learning_rate": 4.0625000000000005e-05, "epoch": 3.018867924528302, "step": 600}, {"loss": 0.93118973, "acc": 0.74165769, "grad_norm": 3.78125, "learning_rate": 3.958333333333333e-05, "epoch": 3.069182389937107, "step": 610}, {"loss": 0.9097496, "acc": 0.74692011, "grad_norm": 3.703125, "learning_rate": 3.854166666666667e-05, "epoch": 3.119496855345912, "step": 620}, {"loss": 0.91313152, "acc": 0.74724779, "grad_norm": 3.75, "learning_rate": 3.7500000000000003e-05, "epoch": 3.169811320754717, "step": 630}, {"loss": 0.89370852, "acc": 0.75153942, "grad_norm": 3.875, "learning_rate": 3.6458333333333336e-05, "epoch": 3.220125786163522, "step": 640}, {"loss": 0.89566641, "acc": 0.75264025, "grad_norm": 3.53125, "learning_rate": 3.541666666666667e-05, "epoch": 3.270440251572327, "step": 650}, {"loss": 0.89889536, "acc": 0.74873405, "grad_norm": 3.6875, "learning_rate": 3.4375e-05, "epoch": 3.3207547169811322, "step": 660}, {"loss": 0.87628231, "acc": 0.75423079, "grad_norm": 3.84375, "learning_rate": 3.3333333333333335e-05, "epoch": 3.3710691823899372, "step": 670}, {"loss": 0.89561214, "acc": 0.75284452, "grad_norm": 3.703125, "learning_rate": 3.229166666666667e-05, "epoch": 3.4213836477987423, "step": 680}, {"loss": 0.89204979, "acc": 0.75219603, "grad_norm": 3.703125, "learning_rate": 3.125e-05, "epoch": 3.4716981132075473, "step": 690}, {"loss": 0.89397411, "acc": 0.75547881, "grad_norm": 4.15625, "learning_rate": 3.0208333333333334e-05, "epoch": 3.5220125786163523, "step": 700}, {"loss": 0.89460144, "acc": 0.75201845, "grad_norm": 3.9375, "learning_rate": 2.916666666666667e-05, "epoch": 3.5723270440251573, "step": 710}, {"loss": 0.89762802, "acc": 0.75330639, "grad_norm": 4.0, "learning_rate": 2.8125000000000003e-05, "epoch": 3.6226415094339623, "step": 720}, {"loss": 0.83859186, "acc": 0.76659098, "grad_norm": 3.828125, "learning_rate": 2.7083333333333332e-05, "epoch": 3.6729559748427674, "step": 730}, {"loss": 0.86151867, "acc": 0.7623024, "grad_norm": 4.21875, "learning_rate": 2.604166666666667e-05, "epoch": 3.7232704402515724, "step": 740}, {"loss": 0.86721306, "acc": 0.75714869, "grad_norm": 3.890625, "learning_rate": 2.5e-05, "epoch": 3.7735849056603774, "step": 750}, {"loss": 0.86395082, "acc": 0.75858154, "grad_norm": 3.90625, "learning_rate": 2.3958333333333334e-05, "epoch": 3.8238993710691824, "step": 760}, {"loss": 0.86485796, "acc": 0.76084099, "grad_norm": 4.09375, "learning_rate": 2.2916666666666667e-05, "epoch": 3.8742138364779874, "step": 770}, {"loss": 0.84113998, "acc": 0.76386518, "grad_norm": 4.15625, "learning_rate": 2.1875e-05, "epoch": 3.9245283018867925, "step": 780}, {"loss": 0.83705759, "acc": 0.76792974, "grad_norm": 4.0, "learning_rate": 2.0833333333333336e-05, "epoch": 3.9748427672955975, "step": 790}, {"loss": 0.83809834, "acc": 0.77246685, "grad_norm": 3.765625, "learning_rate": 1.9791666666666665e-05, "epoch": 4.0251572327044025, "step": 800}, {"loss": 0.73750415, "acc": 0.79452448, "grad_norm": 4.40625, "learning_rate": 1.8750000000000002e-05, "epoch": 4.0754716981132075, "step": 810}, {"loss": 0.74755049, "acc": 0.79700141, "grad_norm": 4.1875, "learning_rate": 1.7708333333333335e-05, "epoch": 4.1257861635220126, "step": 820}, {"loss": 0.71598339, "acc": 0.80311651, "grad_norm": 4.375, "learning_rate": 1.6666666666666667e-05, "epoch": 4.176100628930818, "step": 830}, {"loss": 0.72523293, "acc": 0.79688063, "grad_norm": 4.5, "learning_rate": 1.5625e-05, "epoch": 4.226415094339623, "step": 840}, {"loss": 0.74284472, "acc": 0.79844427, "grad_norm": 4.28125, "learning_rate": 1.4583333333333335e-05, "epoch": 4.276729559748428, "step": 850}, {"loss": 0.750599, "acc": 0.79428258, "grad_norm": 4.4375, "learning_rate": 1.3541666666666666e-05, "epoch": 4.327044025157233, "step": 860}, {"loss": 0.74018383, "acc": 0.79566803, "grad_norm": 4.4375, "learning_rate": 1.25e-05, "epoch": 4.377358490566038, "step": 870}, {"loss": 0.7179245, "acc": 0.80367155, "grad_norm": 4.53125, "learning_rate": 1.1458333333333333e-05, "epoch": 4.427672955974843, "step": 880}, {"loss": 0.73799438, "acc": 0.80155563, "grad_norm": 4.46875, "learning_rate": 1.0416666666666668e-05, "epoch": 4.477987421383648, "step": 890}, {"loss": 0.73876877, "acc": 0.79835653, "grad_norm": 4.125, "learning_rate": 9.375000000000001e-06, "epoch": 4.528301886792453, "step": 900}, {"loss": 0.72253733, "acc": 0.79840956, "grad_norm": 4.34375, "learning_rate": 8.333333333333334e-06, "epoch": 4.578616352201258, "step": 910}, {"loss": 0.7410614, "acc": 0.79425635, "grad_norm": 4.09375, "learning_rate": 7.2916666666666674e-06, "epoch": 4.628930817610063, "step": 920}, {"loss": 0.74439735, "acc": 0.79551425, "grad_norm": 4.34375, "learning_rate": 6.25e-06, "epoch": 4.679245283018868, "step": 930}, {"loss": 0.72431068, "acc": 0.80380936, "grad_norm": 4.15625, "learning_rate": 5.208333333333334e-06, "epoch": 4.729559748427673, "step": 940}, {"loss": 0.74081545, "acc": 0.79461656, "grad_norm": 4.15625, "learning_rate": 4.166666666666667e-06, "epoch": 4.779874213836478, "step": 950}, {"loss": 0.74980698, "acc": 0.79357677, "grad_norm": 4.46875, "learning_rate": 3.125e-06, "epoch": 4.830188679245283, "step": 960}, {"loss": 0.71733956, "acc": 0.80507946, "grad_norm": 4.34375, "learning_rate": 2.0833333333333334e-06, "epoch": 4.880503144654088, "step": 970}, {"loss": 0.71620884, "acc": 0.80562067, "grad_norm": 4.375, "learning_rate": 1.0416666666666667e-06, "epoch": 4.930817610062893, "step": 980}, {"loss": 0.74588747, "acc": 0.799578, "grad_norm": 4.125, "learning_rate": 0.0, "epoch": 4.981132075471698, "step": 990}, {"eval_loss": 1.0441640615463257, "eval_acc": 0.7156441023318995, "eval_runtime": 23.8005, "eval_samples_per_second": 2.731, "eval_steps_per_second": 0.714, "epoch": 4.981132075471698, "step": 990}, {"train_runtime": 23116.3719, "train_samples_per_second": 1.375, "train_steps_per_second": 0.043, "total_flos": 6.158400239163146e+17, "train_loss": 1.1793132555605186, "epoch": 4.981132075471698, "step": 990}], "model_info": "PeftModelForCausalLM: 9670.9599M Params (14.0247M Trainable [0.1450%]), 0.0000M Buffers.", "dataset_info": {"train_dataset": "358.053791\u00b120.710020, min=314.000000, max=518.000000, size=6358", "val_dataset": "359.076923\u00b118.445185, min=326.000000, max=412.000000, size=65"}}
{"memory": {"cuda:0": "28.34GiB", "cuda:1": "0.00GiB", "cuda:2": "0.00GiB", "cuda:3": "0.00GiB"}, "gen_time": 0.0, "gen_len": 0, "train_time": {"train_runtime": 23117.2147, "n_train_samples": 6358, "train_samples_per_second": 0.2750331336413119}, "last_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_model_checkpoint": "/home/image_team/image_team_docker_home/lgd/e_commerce_lmm/results/qwenvl_swift_xray/qwen-vl-chat/v1-20240505-042908/checkpoint-990", "best_metric": 1.04416406, "global_step": 990, "log_history": [{"loss": 4.48069239, "acc": 0.35792518, "grad_norm": 3.828125, "learning_rate": 3.3333333333333333e-06, "epoch": 0.005031446540880503, "step": 1}, {"loss": 4.52559831, "acc": 0.34041935, "grad_norm": 4.09375, "learning_rate": 3.3333333333333335e-05, "epoch": 0.050314465408805034, "step": 10}, {"loss": 3.36858749, "acc": 0.39652653, "grad_norm": 1.3984375, "learning_rate": 6.666666666666667e-05, "epoch": 0.10062893081761007, "step": 20}, {"loss": 2.35984173, "acc": 0.5008389, "grad_norm": 1.3515625, "learning_rate": 0.0001, "epoch": 0.1509433962264151, "step": 30}, {"loss": 2.00753918, "acc": 0.5486455, "grad_norm": 1.15625, "learning_rate": 9.895833333333334e-05, "epoch": 0.20125786163522014, "step": 40}, {"loss": 1.81973248, "acc": 0.56725512, "grad_norm": 1.109375, "learning_rate": 9.791666666666667e-05, "epoch": 0.25157232704402516, "step": 50}, {"loss": 1.79023495, "acc": 0.57348714, "grad_norm": 1.0703125, "learning_rate": 9.687500000000001e-05, "epoch": 0.3018867924528302, "step": 60}, {"loss": 1.72146225, "acc": 0.58238773, "grad_norm": 1.2109375, "learning_rate": 9.583333333333334e-05, "epoch": 0.3522012578616352, "step": 70}, {"loss": 1.58067446, "acc": 0.60350637, "grad_norm": 1.3828125, "learning_rate": 9.479166666666666e-05, "epoch": 0.4025157232704403, "step": 80}, {"loss": 1.64500809, "acc": 0.59458008, "grad_norm": 1.109375, "learning_rate": 9.375e-05, "epoch": 0.4528301886792453, "step": 90}, {"loss": 1.55661736, "acc": 0.60787306, "grad_norm": 1.3359375, "learning_rate": 9.270833333333334e-05, "epoch": 0.5031446540880503, "step": 100}, {"loss": 1.56103096, "acc": 0.60477295, "grad_norm": 1.296875, "learning_rate": 9.166666666666667e-05, "epoch": 0.5534591194968553, "step": 110}, {"loss": 1.55453377, "acc": 0.60405235, "grad_norm": 1.5234375, "learning_rate": 9.062500000000001e-05, "epoch": 0.6037735849056604, "step": 120}, {"loss": 1.53154507, "acc": 0.61138291, "grad_norm": 1.6171875, "learning_rate": 8.958333333333335e-05, "epoch": 0.6540880503144654, "step": 130}, {"loss": 1.52059917, "acc": 0.61493511, "grad_norm": 1.5078125, "learning_rate": 8.854166666666667e-05, "epoch": 0.7044025157232704, "step": 140}, {"loss": 1.4935092, "acc": 0.6185914, "grad_norm": 1.53125, "learning_rate": 8.75e-05, "epoch": 0.7547169811320755, "step": 150}, {"loss": 1.49436073, "acc": 0.62048125, "grad_norm": 1.421875, "learning_rate": 8.645833333333334e-05, "epoch": 0.8050314465408805, "step": 160}, {"loss": 1.49089794, "acc": 0.62400393, "grad_norm": 1.484375, "learning_rate": 8.541666666666666e-05, "epoch": 0.8553459119496856, "step": 170}, {"loss": 1.40507154, "acc": 0.63742633, "grad_norm": 1.5703125, "learning_rate": 8.4375e-05, "epoch": 0.9056603773584906, "step": 180}, {"loss": 1.39483232, "acc": 0.63473172, "grad_norm": 1.515625, "learning_rate": 8.333333333333334e-05, "epoch": 0.9559748427672956, "step": 190}, {"loss": 1.4571373, "acc": 0.62379017, "grad_norm": 1.4296875, "learning_rate": 8.229166666666667e-05, "epoch": 1.0062893081761006, "step": 200}, {"loss": 1.4006216, "acc": 0.63763671, "grad_norm": 1.671875, "learning_rate": 8.125000000000001e-05, "epoch": 1.0566037735849056, "step": 210}, {"loss": 1.35726681, "acc": 0.64623518, "grad_norm": 1.6640625, "learning_rate": 8.020833333333334e-05, "epoch": 1.1069182389937107, "step": 220}, {"loss": 1.36130962, "acc": 0.64660139, "grad_norm": 1.6171875, "learning_rate": 7.916666666666666e-05, "epoch": 1.1572327044025157, "step": 230}, {"loss": 1.35630322, "acc": 0.63943715, "grad_norm": 1.7109375, "learning_rate": 7.8125e-05, "epoch": 1.2075471698113207, "step": 240}, {"loss": 1.32482462, "acc": 0.6509944, "grad_norm": 1.8984375, "learning_rate": 7.708333333333334e-05, "epoch": 1.2578616352201257, "step": 250}, {"loss": 1.32668304, "acc": 0.65223727, "grad_norm": 1.78125, "learning_rate": 7.604166666666667e-05, "epoch": 1.3081761006289307, "step": 260}, {"loss": 1.35992279, "acc": 0.63887272, "grad_norm": 1.890625, "learning_rate": 7.500000000000001e-05, "epoch": 1.3584905660377358, "step": 270}, {"loss": 1.32854404, "acc": 0.64692817, "grad_norm": 1.96875, "learning_rate": 7.395833333333335e-05, "epoch": 1.408805031446541, "step": 280}, {"loss": 1.30504303, "acc": 0.6549881, "grad_norm": 1.90625, "learning_rate": 7.291666666666667e-05, "epoch": 1.459119496855346, "step": 290}, {"loss": 1.31133156, "acc": 0.65215788, "grad_norm": 1.8671875, "learning_rate": 7.1875e-05, "epoch": 1.509433962264151, "step": 300}, {"loss": 1.31055508, "acc": 0.65409498, "grad_norm": 2.015625, "learning_rate": 7.083333333333334e-05, "epoch": 1.559748427672956, "step": 310}, {"loss": 1.27391224, "acc": 0.65717721, "grad_norm": 2.078125, "learning_rate": 6.979166666666666e-05, "epoch": 1.610062893081761, "step": 320}, {"loss": 1.25759382, "acc": 0.66044388, "grad_norm": 2.203125, "learning_rate": 6.875e-05, "epoch": 1.6603773584905661, "step": 330}, {"loss": 1.30579948, "acc": 0.64948182, "grad_norm": 2.125, "learning_rate": 6.770833333333334e-05, "epoch": 1.7106918238993711, "step": 340}, {"loss": 1.25139179, "acc": 0.66449022, "grad_norm": 1.953125, "learning_rate": 6.666666666666667e-05, "epoch": 1.7610062893081762, "step": 350}, {"loss": 1.27490225, "acc": 0.65693283, "grad_norm": 2.109375, "learning_rate": 6.562500000000001e-05, "epoch": 1.8113207547169812, "step": 360}, {"loss": 1.28073511, "acc": 0.6558342, "grad_norm": 2.09375, "learning_rate": 6.458333333333334e-05, "epoch": 1.8616352201257862, "step": 370}, {"loss": 1.25887384, "acc": 0.65924997, "grad_norm": 2.28125, "learning_rate": 6.354166666666666e-05, "epoch": 1.9119496855345912, "step": 380}, {"loss": 1.2434267, "acc": 0.66663504, "grad_norm": 2.109375, "learning_rate": 6.25e-05, "epoch": 1.9622641509433962, "step": 390}, {"loss": 1.20375528, "acc": 0.67453065, "grad_norm": 2.1875, "learning_rate": 6.145833333333334e-05, "epoch": 2.0125786163522013, "step": 400}, {"loss": 1.10296974, "acc": 0.69613857, "grad_norm": 2.796875, "learning_rate": 6.041666666666667e-05, "epoch": 2.0628930817610063, "step": 410}, {"loss": 1.1419445, "acc": 0.68712835, "grad_norm": 2.5, "learning_rate": 5.9375e-05, "epoch": 2.1132075471698113, "step": 420}, {"loss": 1.11612244, "acc": 0.69560375, "grad_norm": 2.765625, "learning_rate": 5.833333333333334e-05, "epoch": 2.1635220125786163, "step": 430}, {"loss": 1.08185406, "acc": 0.7032136, "grad_norm": 2.4375, "learning_rate": 5.7291666666666666e-05, "epoch": 2.2138364779874213, "step": 440}, {"loss": 1.13129711, "acc": 0.69179592, "grad_norm": 2.796875, "learning_rate": 5.6250000000000005e-05, "epoch": 2.2641509433962264, "step": 450}, {"loss": 1.10817566, "acc": 0.69704566, "grad_norm": 2.765625, "learning_rate": 5.520833333333334e-05, "epoch": 2.3144654088050314, "step": 460}, {"loss": 1.1209919, "acc": 0.69373083, "grad_norm": 2.53125, "learning_rate": 5.4166666666666664e-05, "epoch": 2.3647798742138364, "step": 470}, {"loss": 1.08133392, "acc": 0.69915276, "grad_norm": 2.84375, "learning_rate": 5.3125000000000004e-05, "epoch": 2.4150943396226414, "step": 480}, {"loss": 1.09620447, "acc": 0.70328555, "grad_norm": 3.09375, "learning_rate": 5.208333333333334e-05, "epoch": 2.4654088050314464, "step": 490}, {"loss": 1.10145006, "acc": 0.69386168, "grad_norm": 2.625, "learning_rate": 5.104166666666666e-05, "epoch": 2.5157232704402515, "step": 500}, {"loss": 1.09908714, "acc": 0.70252738, "grad_norm": 2.828125, "learning_rate": 5e-05, "epoch": 2.5660377358490565, "step": 510}, {"loss": 1.10869875, "acc": 0.69673443, "grad_norm": 3.0625, "learning_rate": 4.8958333333333335e-05, "epoch": 2.6163522012578615, "step": 520}, {"loss": 1.10360785, "acc": 0.69666939, "grad_norm": 3.15625, "learning_rate": 4.791666666666667e-05, "epoch": 2.6666666666666665, "step": 530}, {"loss": 1.06053267, "acc": 0.70942111, "grad_norm": 3.21875, "learning_rate": 4.6875e-05, "epoch": 2.7169811320754715, "step": 540}, {"loss": 1.11005697, "acc": 0.69621105, "grad_norm": 3.21875, "learning_rate": 4.5833333333333334e-05, "epoch": 2.767295597484277, "step": 550}, {"loss": 1.07346964, "acc": 0.70517683, "grad_norm": 3.140625, "learning_rate": 4.4791666666666673e-05, "epoch": 2.817610062893082, "step": 560}, {"loss": 1.07415762, "acc": 0.70620279, "grad_norm": 3.15625, "learning_rate": 4.375e-05, "epoch": 2.867924528301887, "step": 570}, {"loss": 1.054006, "acc": 0.71239042, "grad_norm": 3.34375, "learning_rate": 4.270833333333333e-05, "epoch": 2.918238993710692, "step": 580}, {"loss": 1.03590345, "acc": 0.71305399, "grad_norm": 3.234375, "learning_rate": 4.166666666666667e-05, "epoch": 2.968553459119497, "step": 590}, {"loss": 1.02116022, "acc": 0.71916242, "grad_norm": 3.1875, "learning_rate": 4.0625000000000005e-05, "epoch": 3.018867924528302, "step": 600}, {"loss": 0.93118973, "acc": 0.74165769, "grad_norm": 3.78125, "learning_rate": 3.958333333333333e-05, "epoch": 3.069182389937107, "step": 610}, {"loss": 0.9097496, "acc": 0.74692011, "grad_norm": 3.703125, "learning_rate": 3.854166666666667e-05, "epoch": 3.119496855345912, "step": 620}, {"loss": 0.91313152, "acc": 0.74724779, "grad_norm": 3.75, "learning_rate": 3.7500000000000003e-05, "epoch": 3.169811320754717, "step": 630}, {"loss": 0.89370852, "acc": 0.75153942, "grad_norm": 3.875, "learning_rate": 3.6458333333333336e-05, "epoch": 3.220125786163522, "step": 640}, {"loss": 0.89566641, "acc": 0.75264025, "grad_norm": 3.53125, "learning_rate": 3.541666666666667e-05, "epoch": 3.270440251572327, "step": 650}, {"loss": 0.89889536, "acc": 0.74873405, "grad_norm": 3.6875, "learning_rate": 3.4375e-05, "epoch": 3.3207547169811322, "step": 660}, {"loss": 0.87628231, "acc": 0.75423079, "grad_norm": 3.84375, "learning_rate": 3.3333333333333335e-05, "epoch": 3.3710691823899372, "step": 670}, {"loss": 0.89561214, "acc": 0.75284452, "grad_norm": 3.703125, "learning_rate": 3.229166666666667e-05, "epoch": 3.4213836477987423, "step": 680}, {"loss": 0.89204979, "acc": 0.75219603, "grad_norm": 3.703125, "learning_rate": 3.125e-05, "epoch": 3.4716981132075473, "step": 690}, {"loss": 0.89397411, "acc": 0.75547881, "grad_norm": 4.15625, "learning_rate": 3.0208333333333334e-05, "epoch": 3.5220125786163523, "step": 700}, {"loss": 0.89460144, "acc": 0.75201845, "grad_norm": 3.9375, "learning_rate": 2.916666666666667e-05, "epoch": 3.5723270440251573, "step": 710}, {"loss": 0.89762802, "acc": 0.75330639, "grad_norm": 4.0, "learning_rate": 2.8125000000000003e-05, "epoch": 3.6226415094339623, "step": 720}, {"loss": 0.83859186, "acc": 0.76659098, "grad_norm": 3.828125, "learning_rate": 2.7083333333333332e-05, "epoch": 3.6729559748427674, "step": 730}, {"loss": 0.86151867, "acc": 0.7623024, "grad_norm": 4.21875, "learning_rate": 2.604166666666667e-05, "epoch": 3.7232704402515724, "step": 740}, {"loss": 0.86721306, "acc": 0.75714869, "grad_norm": 3.890625, "learning_rate": 2.5e-05, "epoch": 3.7735849056603774, "step": 750}, {"loss": 0.86395082, "acc": 0.75858154, "grad_norm": 3.90625, "learning_rate": 2.3958333333333334e-05, "epoch": 3.8238993710691824, "step": 760}, {"loss": 0.86485796, "acc": 0.76084099, "grad_norm": 4.09375, "learning_rate": 2.2916666666666667e-05, "epoch": 3.8742138364779874, "step": 770}, {"loss": 0.84113998, "acc": 0.76386518, "grad_norm": 4.15625, "learning_rate": 2.1875e-05, "epoch": 3.9245283018867925, "step": 780}, {"loss": 0.83705759, "acc": 0.76792974, "grad_norm": 4.0, "learning_rate": 2.0833333333333336e-05, "epoch": 3.9748427672955975, "step": 790}, {"loss": 0.83809834, "acc": 0.77246685, "grad_norm": 3.765625, "learning_rate": 1.9791666666666665e-05, "epoch": 4.0251572327044025, "step": 800}, {"loss": 0.73750415, "acc": 0.79452448, "grad_norm": 4.40625, "learning_rate": 1.8750000000000002e-05, "epoch": 4.0754716981132075, "step": 810}, {"loss": 0.74755049, "acc": 0.79700141, "grad_norm": 4.1875, "learning_rate": 1.7708333333333335e-05, "epoch": 4.1257861635220126, "step": 820}, {"loss": 0.71598339, "acc": 0.80311651, "grad_norm": 4.375, "learning_rate": 1.6666666666666667e-05, "epoch": 4.176100628930818, "step": 830}, {"loss": 0.72523293, "acc": 0.79688063, "grad_norm": 4.5, "learning_rate": 1.5625e-05, "epoch": 4.226415094339623, "step": 840}, {"loss": 0.74284472, "acc": 0.79844427, "grad_norm": 4.28125, "learning_rate": 1.4583333333333335e-05, "epoch": 4.276729559748428, "step": 850}, {"loss": 0.750599, "acc": 0.79428258, "grad_norm": 4.4375, "learning_rate": 1.3541666666666666e-05, "epoch": 4.327044025157233, "step": 860}, {"loss": 0.74018383, "acc": 0.79566803, "grad_norm": 4.4375, "learning_rate": 1.25e-05, "epoch": 4.377358490566038, "step": 870}, {"loss": 0.7179245, "acc": 0.80367155, "grad_norm": 4.53125, "learning_rate": 1.1458333333333333e-05, "epoch": 4.427672955974843, "step": 880}, {"loss": 0.73799438, "acc": 0.80155563, "grad_norm": 4.46875, "learning_rate": 1.0416666666666668e-05, "epoch": 4.477987421383648, "step": 890}, {"loss": 0.73876877, "acc": 0.79835653, "grad_norm": 4.125, "learning_rate": 9.375000000000001e-06, "epoch": 4.528301886792453, "step": 900}, {"loss": 0.72253733, "acc": 0.79840956, "grad_norm": 4.34375, "learning_rate": 8.333333333333334e-06, "epoch": 4.578616352201258, "step": 910}, {"loss": 0.7410614, "acc": 0.79425635, "grad_norm": 4.09375, "learning_rate": 7.2916666666666674e-06, "epoch": 4.628930817610063, "step": 920}, {"loss": 0.74439735, "acc": 0.79551425, "grad_norm": 4.34375, "learning_rate": 6.25e-06, "epoch": 4.679245283018868, "step": 930}, {"loss": 0.72431068, "acc": 0.80380936, "grad_norm": 4.15625, "learning_rate": 5.208333333333334e-06, "epoch": 4.729559748427673, "step": 940}, {"loss": 0.74081545, "acc": 0.79461656, "grad_norm": 4.15625, "learning_rate": 4.166666666666667e-06, "epoch": 4.779874213836478, "step": 950}, {"loss": 0.74980698, "acc": 0.79357677, "grad_norm": 4.46875, "learning_rate": 3.125e-06, "epoch": 4.830188679245283, "step": 960}, {"loss": 0.71733956, "acc": 0.80507946, "grad_norm": 4.34375, "learning_rate": 2.0833333333333334e-06, "epoch": 4.880503144654088, "step": 970}, {"loss": 0.71620884, "acc": 0.80562067, "grad_norm": 4.375, "learning_rate": 1.0416666666666667e-06, "epoch": 4.930817610062893, "step": 980}, {"loss": 0.74588747, "acc": 0.799578, "grad_norm": 4.125, "learning_rate": 0.0, "epoch": 4.981132075471698, "step": 990}, {"eval_loss": 1.0441640615463257, "eval_acc": 0.7156441023318995, "eval_runtime": 23.7999, "eval_samples_per_second": 2.731, "eval_steps_per_second": 0.714, "epoch": 4.981132075471698, "step": 990}, {"train_runtime": 23117.2147, "train_samples_per_second": 1.375, "train_steps_per_second": 0.043, "total_flos": 6.158400239163146e+17, "train_loss": 1.1793132555605186, "epoch": 4.981132075471698, "step": 990}], "model_info": "PeftModelForCausalLM: 9670.9599M Params (14.0247M Trainable [0.1450%]), 0.0000M Buffers.", "dataset_info": {"train_dataset": "358.053791\u00b120.710020, min=314.000000, max=518.000000, size=6358", "val_dataset": "359.076923\u00b118.445185, min=326.000000, max=412.000000, size=65"}}
